<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CSM 02 - H2,H8,J3 - DL Project</title>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/face-api.js/0.22.2/face-api.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: white;
            color: black;
            line-height: 1.6;
        }

        header {
            text-align: center;
            padding: 2rem 1rem;
            border-bottom: 2px solid black;
        }

        h1 {
            font-size: 2rem;
            margin-bottom: 0.5rem;
            font-weight: 700;
        }

        .instructions {
            font-size: 0.95rem;
            max-width: 600px;
            margin: 0 auto;
        }

        .privacy-notice {
            font-size: 0.85rem;
            margin-top: 0.5rem;
            opacity: 0.7;
        }

        main {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 1rem;
        }

        .panel {
            border: 2px solid black;
            padding: 1.5rem;
            min-height: 400px;
        }

        .panel h2 {
            font-size: 1.25rem;
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .input-buttons {
            display: flex;
            gap: 1rem;
            margin-bottom: 1.5rem;
            flex-wrap: wrap;
        }

        button {
            flex: 1;
            min-width: 120px;
            padding: 0.75rem 1.5rem;
            background: black;
            color: white;
            border: none;
            cursor: pointer;
            font-size: 1rem;
            font-weight: 500;
            transition: opacity 0.2s;
        }

        button:hover:not(:disabled) {
            opacity: 0.8;
        }

        button:disabled {
            opacity: 0.4;
            cursor: not-allowed;
        }

        input[type="file"] {
            display: none;
        }

        .preview-container {
            position: relative;
            width: 100%;
            min-height: 300px;
            border: 1px solid black;
            display: flex;
            align-items: center;
            justify-content: center;
            background: white;
        }

        .preview-container img, .preview-container video {
            max-width: 100%;
            max-height: 400px;
            display: block;
        }

        .placeholder {
            color: rgba(0, 0, 0, 0.4);
            text-align: center;
            padding: 2rem;
        }

        .scanning-overlay {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(255, 255, 255, 0.9);
            display: none;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 10;
        }

        .scanning-overlay.active {
            display: flex;
        }

        .scanning-text {
            font-size: 1.1rem;
            margin-bottom: 1rem;
            font-weight: 500;
        }

        .progress-bar {
            width: 80%;
            height: 4px;
            background: rgba(0, 0, 0, 0.1);
            position: relative;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: black;
            width: 0%;
            transition: width 0.1s linear;
        }

        .result-container {
            text-align: center;
        }

        .emoji-display {
            font-size: 8rem;
            margin: 2rem 0;
            animation: emojiPop 0.5s ease-out;
        }

        @keyframes emojiPop {
            0% { transform: scale(0); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }

        .expression-label {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
            text-transform: capitalize;
        }

        .confidence {
            font-size: 1rem;
            opacity: 0.7;
        }

        .error-message {
            color: black;
            background: white;
            border: 2px solid black;
            padding: 1rem;
            margin-top: 1rem;
            text-align: center;
        }

        .hidden {
            display: none;
        }

        @media (max-width: 768px) {
            main {
                grid-template-columns: 1fr;
            }
            
            h1 {
                font-size: 1.5rem;
            }
            
            .emoji-display {
                font-size: 5rem;
            }
        }

        .loading-models {
            text-align: center;
            padding: 2rem;
            font-size: 0.9rem;
        }

        .loading-spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 2px solid rgba(0, 0, 0, 0.1);
            border-top: 2px solid black;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-right: 0.5rem;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <header>
        <h1>DL Project(Facial expression to emoji conversion)</h1>
        <p class="instructions">
            Capture or upload a photo to analyze your facial expression and discover your matching emoji!
        </p>
        <p class="privacy-notice">
            üîí All processing happens in your Laptop. No images are uploaded or stored.
        </p>
    </header>

    <main>
        <div class="panel">
            <h2>Input</h2>
            <div id="loadingModels" class="loading-models">
                <div class="loading-spinner"></div>
                Loading face detection models...
            </div>
            <div id="inputControls" class="hidden">
                <div class="input-buttons">
                    <button id="cameraBtn" aria-label="Capture from camera">üì∑ Camera</button>
                    <button id="uploadBtn" aria-label="Upload image">üìÅ Upload</button>
                    <input type="file" id="fileInput" accept="image/jpeg,image/png" />
                </div>
                <div class="preview-container" id="previewContainer">
                    <div class="placeholder">
                        Select camera or upload an image to begin
                    </div>
                    <div class="scanning-overlay" id="scanningOverlay">
                        <div class="scanning-text">Analyzing facial expression...</div>
                        <div class="progress-bar">
                            <div class="progress-fill" id="progressFill"></div>
                        </div>
                    </div>
                </div>
                <div id="errorMessage" class="error-message hidden"></div>
            </div>
        </div>

        <div class="panel">
            <h2>Result</h2>
            <div id="resultContainer" class="result-container hidden">
                <div class="emoji-display" id="emojiDisplay"></div>
                <div class="expression-label" id="expressionLabel"></div>
                <div class="confidence" id="confidenceScore"></div>
            </div>
            <div id="resultPlaceholder" class="placeholder">
                Your emoji match will appear here
            </div>
        </div>
    </main>

    <script>
        // Emoji mapping for each expression detected by face-api.js
        const EXPRESSION_EMOJI_MAP = {
            happy: 'üòä',
            sad: 'üò¢',
            angry: 'üò†',
            disgusted: 'ü§¢',
            surprised: 'üòÆ',
            fearful: 'üò®',
            neutral: 'üòê'
        };

        let modelsLoaded = false;
        let currentStream = null;

        // Load face-api.js models from CDN
        async function loadModels() {
            try {
                const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/';
                
                // Load required models: TinyFaceDetector (lightweight), FaceLandmarks, FaceExpressionRecognition
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
                await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
                
                modelsLoaded = true;
                document.getElementById('loadingModels').classList.add('hidden');
                document.getElementById('inputControls').classList.remove('hidden');
            } catch (error) {
                showError('Failed to load face detection models. Please refresh the page.');
                console.error('Model loading error:', error);
            }
        }

        // Analyze face and detect expression
        async function analyzeFace(imageElement) {
            if (!modelsLoaded) {
                showError('Models not loaded yet. Please wait.');
                return;
            }

            hideError();
            showScanning();

            try {
                // Start 8-second progress animation
                animateProgress(8000);

                // Detect face with expressions using TinyFaceDetector (faster, good for client-side)
                const detection = await faceapi
                    .detectSingleFace(imageElement, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceExpressions();

                // Wait for animation to complete (minimum 8 seconds)
                await new Promise(resolve => setTimeout(resolve, 8000));

                hideScanning();

                if (!detection) {
                    showError('No face detected. Please try another image with a clear face.');
                    return;
                }

                // Get the dominant expression (highest probability)
                const expressions = detection.expressions;
                const sortedExpressions = Object.entries(expressions).sort((a, b) => b[1] - a[1]);
                const [dominantExpression, confidence] = sortedExpressions[0];

                // Check confidence threshold
                if (confidence < 0.3) {
                    showError('Low confidence in expression detection. Please try another image.');
                    return;
                }

                // Display result
                displayResult(dominantExpression, confidence);

            } catch (error) {
                hideScanning();
                showError('Error analyzing face. Please try again.');
                console.error('Analysis error:', error);
            }
        }

        // Animate progress bar over specified duration
        function animateProgress(duration) {
            const fill = document.getElementById('progressFill');
            const startTime = Date.now();
            
            function update() {
                const elapsed = Date.now() - startTime;
                const progress = Math.min((elapsed / duration) * 100, 100);
                fill.style.width = progress + '%';
                
                if (progress < 100) {
                    requestAnimationFrame(update);
                }
            }
            
            update();
        }

        // Display emoji result
        function displayResult(expression, confidence) {
            const emoji = EXPRESSION_EMOJI_MAP[expression] || 'ü§î';
            
            document.getElementById('emojiDisplay').textContent = emoji;
            document.getElementById('expressionLabel').textContent = expression;
            document.getElementById('confidenceScore').textContent = 
                `${(confidence * 100).toFixed(1)}% confidence`;
            
            document.getElementById('resultPlaceholder').classList.add('hidden');
            document.getElementById('resultContainer').classList.remove('hidden');
        }

        // Show/hide scanning overlay
        function showScanning() {
            document.getElementById('scanningOverlay').classList.add('active');
            document.getElementById('progressFill').style.width = '0%';
        }

        function hideScanning() {
            document.getElementById('scanningOverlay').classList.remove('active');
        }

        // Error handling
        function showError(message) {
            const errorEl = document.getElementById('errorMessage');
            errorEl.textContent = message;
            errorEl.classList.remove('hidden');
        }

        function hideError() {
            document.getElementById('errorMessage').classList.add('hidden');
        }

        // Camera capture
        document.getElementById('cameraBtn').addEventListener('click', async () => {
            try {
                // Stop any existing stream
                if (currentStream) {
                    currentStream.getTracks().forEach(track => track.stop());
                }

                // Request camera access
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'user' } 
                });
                currentStream = stream;

                const video = document.createElement('video');
                video.srcObject = stream;
                video.autoplay = true;
                video.playsInline = true;

                const container = document.getElementById('previewContainer');
                container.innerHTML = '';
                container.appendChild(video);

                // Wait for video to be ready, then capture frame
                video.addEventListener('loadedmetadata', () => {
                    setTimeout(() => {
                        const canvas = document.createElement('canvas');
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        const ctx = canvas.getContext('2d');
                        ctx.drawImage(video, 0, 0);

                        // Convert to image and analyze
                        const img = new Image();
                        img.src = canvas.toDataURL();
                        img.onload = () => {
                            container.innerHTML = '';
                            container.appendChild(img);
                            
                            // Stop camera stream
                            stream.getTracks().forEach(track => track.stop());
                            currentStream = null;

                            // Analyze the captured image
                            analyzeFace(img);
                        };
                    }, 100);
                });

            } catch (error) {
                if (error.name === 'NotAllowedError') {
                    showError('Camera permission denied. Please enable camera access.');
                } else if (error.name === 'NotFoundError') {
                    showError('No camera found on this device.');
                } else {
                    showError('Error accessing camera. Please try uploading an image instead.');
                }
                console.error('Camera error:', error);
            }
        });

        // File upload
        document.getElementById('uploadBtn').addEventListener('click', () => {
            document.getElementById('fileInput').click();
        });

        document.getElementById('fileInput').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;

            if (!file.type.match('image/jpeg') && !file.type.match('image/png')) {
                showError('Please upload a JPG or PNG image.');
                return;
            }

            const reader = new FileReader();
            reader.onload = (event) => {
                const img = new Image();
                img.onload = () => {
                    const container = document.getElementById('previewContainer');
                    container.innerHTML = '';
                    container.appendChild(img);
                    
                    // Analyze the uploaded image
                    analyzeFace(img);
                };
                img.src = event.target.result;
            };
            reader.readAsDataURL(file);
        });

        // Initialize: Load models when page loads
        window.addEventListener('load', () => {
            if (typeof faceapi === 'undefined') {
                showError('Face detection library failed to load. Please refresh the page.');
                return;
            }
            loadModels();
        });

        // Cleanup camera stream on page unload
        window.addEventListener('beforeunload', () => {
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>
